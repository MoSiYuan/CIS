# åˆ†å¸ƒå¼DAGåè°ƒæ¶æ„è®¾è®¡

## æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CIS é›†ç¾¤                                    â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Node-1  â”‚   â”‚ Node-2  â”‚   â”‚ Node-3  â”‚   â”‚ Node-4  â”‚   â”‚5cloud  â”‚ â”‚
â”‚  â”‚(Worker) â”‚   â”‚(Worker) â”‚   â”‚(Worker) â”‚   â”‚(Worker) â”‚   â”‚(Entry) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚             â”‚             â”‚             â”‚            â”‚      â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚      â”‚
â”‚                         â”‚                                     â”‚      â”‚
â”‚                         â–¼                                     â”‚      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚      â”‚
â”‚              â”‚   Matrix Room       â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â”‚  (!tasks:example)   â”‚                                 â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                         â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ä»»åŠ¡è®¤é¢†ä¸æ‰§è¡Œæµç¨‹                                â”‚
â”‚                                                                      â”‚
â”‚  é˜¶æ®µ1: ä»»åŠ¡å¹¿æ’­                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚  5cloud â”€â”€â–¶ Room: "æ–°DAG: backup_daily, target: node-1, scope: proj-a" â”‚
â”‚                                                                      â”‚
â”‚  é˜¶æ®µ2: èŠ‚ç‚¹è®¤é¢† (Node-1)                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  Node-1: "æˆ‘åŒ¹é…targetï¼Œæˆ‘æ¥è®¤é¢†"                                      â”‚
â”‚    â”œâ”€â”€ å†™å…¥å…¬åŸŸè®°å¿†: "DAG backup_daily å½’æˆ‘æ‰§è¡Œ"                       â”‚
â”‚    â”œâ”€â”€ å†™å…¥DAGè¡¨: status=PENDING, owner=node-1                        â”‚
â”‚    â””â”€â”€ å°è¯•å¯åŠ¨ singleton-agent-DAG                                   â”‚
â”‚                                                                      â”‚
â”‚  é˜¶æ®µ3: å•ä¾‹åè°ƒå™¨å¯åŠ¨ (Node-1 æœ¬åœ°)                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  singleton-agent-DAG:                                                  â”‚
â”‚    â”œâ”€â”€ æ£€æŸ¥ scope=proj-a æ˜¯å¦å·²æœ‰ worker                               â”‚
â”‚    â”‚   â”œâ”€â”€ æœ‰ â†’ å¤ç”¨ç°æœ‰ worker                                        â”‚
â”‚    â”‚   â””â”€â”€ æ—  â†’ å¯åŠ¨æ–° agent-worker-proj-a                             â”‚
â”‚    â””â”€â”€ å°†DAGä»»åŠ¡åˆ†é…ç»™ agent-worker                                    â”‚
â”‚                                                                      â”‚
â”‚  é˜¶æ®µ4: ä»»åŠ¡æ‰§è¡Œ (agent-worker-proj-a)                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  agent-worker:                                                         â”‚
â”‚    â”œâ”€â”€ ä»é˜Ÿåˆ—é¢†å–ä»»åŠ¡                                                  â”‚
â”‚    â”œâ”€â”€ æ‰§è¡Œ (shell/skill)                                              â”‚
â”‚    â”œâ”€â”€ æ›´æ–°çŠ¶æ€åˆ°å…¬åŸŸè®°å¿†                                              â”‚
â”‚    â””â”€â”€ å®Œæˆåé€€å‡ºæˆ–ç­‰å¾…æ–°ä»»åŠ¡                                          â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ ¸å¿ƒæ¦‚å¿µ

### 1. ä½œç”¨åŸŸ (Scope)
```rust
/// ä»»åŠ¡æ‰§è¡Œçš„ä½œç”¨åŸŸï¼ŒåŒä¸€ä½œç”¨åŸŸåªæœ‰ä¸€ä¸ªworker
pub enum TaskScope {
    /// é¡¹ç›®çº§åˆ«éš”ç¦»
    Project(String),      // e.g., "proj-a", "proj-b"
    
    /// ç”¨æˆ·çº§åˆ«éš”ç¦»  
    User(String),         // e.g., "user-123"
    
    /// DAGç±»å‹éš”ç¦»
    DagType(String),      // e.g., "backup", "deploy", "test"
    
    /// å…¨å±€å”¯ä¸€ï¼ˆæ•´ä¸ªé›†ç¾¤ä¸€ä¸ªworkerï¼‰
    Global,
}

/// ä½œç”¨åŸŸå†³å®šäº†workerçš„å¯åŠ¨ç­–ç•¥
impl TaskScope {
    pub fn worker_name(&self) -> String {
        match self {
            TaskScope::Project(p) => format!("worker-project-{}", p),
            TaskScope::User(u) => format!("worker-user-{}", u),
            TaskScope::DagType(t) => format!("worker-type-{}", t),
            TaskScope::Global => "worker-global".to_string(),
        }
    }
}
```

### 2. å•ä¾‹agent-DAG (Singleton Coordinator)
```rust
/// æ¯ä¸ªèŠ‚ç‚¹æœ¬åœ°åªæœ‰ä¸€ä¸ªï¼Œè´Ÿè´£ç®¡ç†è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰worker
pub struct SingletonDagCoordinator {
    node_id: String,
    
    /// ç®¡ç†çš„workers: scope -> worker handle
    workers: HashMap<TaskScope, WorkerHandle>,
    
    /// ä»»åŠ¡é˜Ÿåˆ—
    task_queue: Arc<Mutex<VecDeque<DagTask>>>,
}

impl SingletonDagCoordinator {
    /// å…¨å±€å•ä¾‹ï¼ˆèŠ‚ç‚¹å†…ï¼‰
    pub fn instance() -> Arc<Self> { ... }
    
    /// å¤„ç†æ–°DAG
    pub async fn handle_new_dag(&self, dag: DagDefinition) -> Result<()> {
        // 1. ç¡®å®šä½œç”¨åŸŸ
        let scope = dag.get_scope();
        
        // 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰worker
        if let Some(worker) = self.workers.get(&scope) {
            // å¤ç”¨ç°æœ‰worker
            worker.submit_dag(dag).await?;
        } else {
            // å¯åŠ¨æ–°worker
            let worker = self.spawn_worker(scope.clone()).await?;
            worker.submit_dag(dag).await?;
            self.workers.insert(scope, worker);
        }
        
        Ok(())
    }
    
    /// å¯åŠ¨workerè¿›ç¨‹/çº¿ç¨‹
    async fn spawn_worker(&self, scope: TaskScope) -> Result<WorkerHandle> {
        let worker_name = scope.worker_name();
        
        // å¯åŠ¨ç‹¬ç«‹è¿›ç¨‹
        let child = Command::new("cis-agent-worker")
            .arg("--name", &worker_name)
            .arg("--scope", &scope.to_string())
            .arg("--node", &self.node_id)
            .spawn()?;
        
        Ok(WorkerHandle { process: child, scope })
    }
}
```

### 3. agent-worker (ä½œç”¨åŸŸæ‰§è¡Œå™¨)
```rust
/// ç‰¹å®šä½œç”¨åŸŸçš„ä»»åŠ¡æ‰§è¡Œå™¨
/// åŒä¸€ä½œç”¨åŸŸå…¨å±€åªæœ‰ä¸€ä¸ªå®ä¾‹è¿è¡Œ
pub struct AgentWorker {
    name: String,
    scope: TaskScope,
    node_id: String,
    
    /// æœ¬åœ°ä»»åŠ¡é˜Ÿåˆ—
    local_queue: VecDeque<DagTask>,
    
    /// æ‰§è¡ŒçŠ¶æ€
    status: WorkerStatus,
}

impl AgentWorker {
    pub async fn run(&mut self) {
        loop {
            // 1. ä»é˜Ÿåˆ—å–ä»»åŠ¡
            if let Some(task) = self.local_queue.pop_front() {
                // 2. æ‰§è¡Œ
                let result = self.execute_task(task).await;
                
                // 3. æ›´æ–°å…¬åŸŸè®°å¿†
                self.update_public_memory(&result).await;
            }
            
            // 4. æ£€æŸ¥æ˜¯å¦éœ€è¦é€€å‡ºï¼ˆç©ºé—²è¶…æ—¶ï¼‰
            if self.should_exit() {
                break;
            }
            
            tokio::time::sleep(Duration::from_secs(1)).await;
        }
    }
    
    async fn execute_task(&self, task: DagTask) -> TaskResult {
        match task.task_type {
            TaskType::Shell => self.run_shell(&task).await,
            TaskType::Skill => self.run_skill(&task).await,
            TaskType::Matrix => self.send_matrix(&task).await,
        }
    }
}
```

---

## åˆ†å¸ƒå¼è®¤é¢†æœºåˆ¶

### é—®é¢˜ï¼šå¦‚ä½•é¿å…å¤šèŠ‚ç‚¹åŒæ—¶è®¤é¢†ï¼Ÿ

#### æ–¹æ¡ˆAï¼šRoomæ¶ˆæ¯é¡ºåº + ç¬¬ä¸€ä¸ªå“åº”
```rust
/// è®¤é¢†åè®®
pub struct DagClaimProtocol {
    /// å¹¿æ’­è®¤é¢†æ„å‘
    pub async fn broadcast_intent(&self, dag_id: &str) {
        let msg = json!({
            "type": "dag_claim_intent",
            "dag_id": dag_id,
            "claimer": self.node_id,
            "timestamp": now(),
        });
        
        self.room.send(msg.to_string()).await;
    }
    
    /// ç›‘å¬è®¤é¢†å“åº”ï¼Œç¬¬ä¸€ä¸ªç¡®è®¤çš„è·å¾—æ‰§è¡Œæƒ
    pub async fn wait_for_claim_result(&self, dag_id: &str) -> bool {
        let mut events = self.room.events();
        
        while let Some(event) = events.next().await {
            if let Ok(msg) = serde_json::from_str::<ClaimMessage>(&event.content) {
                if msg.dag_id == dag_id {
                    // æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå·±ç¬¬ä¸€ä¸ªå‘é€çš„
                    return msg.claimer == self.node_id;
                }
            }
        }
        
        false
    }
}
```

#### æ–¹æ¡ˆBï¼šå…¬åŸŸè®°å¿†CASï¼ˆæ¨èï¼‰
```rust
/// åŸºäºå…¬åŸŸè®°å¿†çš„ä¹è§‚é”è®¤é¢†
pub async fn claim_dag_via_memory(&self, dag_id: &str) -> Result<bool> {
    let claim_key = format!("dag:{}/claim", dag_id);
    
    // 1. å°è¯•å†™å…¥è®¤é¢†ä¿¡æ¯
    let claim_info = json!({
        "node_id": self.node_id,
        "claimed_at": now(),
        "status": "claiming",
    });
    
    // 2. CASæ“ä½œï¼šåªæœ‰keyä¸å­˜åœ¨æ—¶æ‰å†™å…¥
    let result = self.memory_service.cas(
        &claim_key,
        None,  // æœŸæœ›å€¼ï¼šä¸å­˜åœ¨
        Some(claim_info.to_string()),  // æ–°å€¼
        MemoryDomain::Public,
    ).await?;
    
    if result.success {
        // è®¤é¢†æˆåŠŸï¼Œç°åœ¨å†™å…¥DAGåˆ°æœ¬åœ°
        self.persist_dag(dag_id).await?;
        
        // æ›´æ–°çŠ¶æ€ä¸ºclaimed
        self.memory_service.set(
            &claim_key,
            json!({"status": "claimed", "node_id": self.node_id}),
            MemoryDomain::Public,
        ).await?;
        
        Ok(true)
    } else {
        // å·²è¢«å…¶ä»–èŠ‚ç‚¹è®¤é¢†
        Ok(false)
    }
}
```

#### æ–¹æ¡ˆCï¼šSQLiteåˆ†å¸ƒå¼é”ï¼ˆåŸºäºRoomï¼‰
```rust
/// åˆ©ç”¨Roomçš„CRDTç‰¹æ€§å®ç°åˆ†å¸ƒå¼é”
/// æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰SQLiteå‰¯æœ¬ï¼Œé€šè¿‡RoomåŒæ­¥
pub struct DistributedLock {
    room: MatrixRoom,
}

impl DistributedLock {
    /// å°è¯•è·å–é”
    pub async fn try_lock(&self, lock_name: &str) -> Result<LockGuard> {
        // å†™å…¥é”è¯·æ±‚åˆ°Room
        let lock_req = LockRequest {
            name: lock_name.to_string(),
            node_id: self.node_id.clone(),
            timestamp: now(),
        };
        
        self.room.send(lock_req.to_json()).await?;
        
        // ç­‰å¾…åŒæ­¥ï¼ˆCRDTä¿è¯æœ€ç»ˆä¸€è‡´ï¼‰
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        // æŸ¥è¯¢æœ¬åœ°SQLiteï¼ˆå·²é€šè¿‡RoomåŒæ­¥ï¼‰
        let holder = self.db.query_row(
            "SELECT node_id FROM distributed_locks WHERE name = ?1",
            [lock_name],
        )?;
        
        if holder == self.node_id {
            Ok(LockGuard { name: lock_name.to_string() })
        } else {
            Err(LockError::AlreadyHeld(holder))
        }
    }
}
```

---

## å®Œæ•´æµç¨‹æ—¶åºå›¾

```
5cloud          Room           Node-1          Node-2       Node-3
  â”‚              â”‚               â”‚               â”‚            â”‚
  â”‚ 1. publish   â”‚               â”‚               â”‚            â”‚
  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶               â”‚               â”‚            â”‚
  â”‚              â”‚ 2. broadcast  â”‚               â”‚            â”‚
  â”‚              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
  â”‚              â”‚               â”‚               â”‚            â”‚
  â”‚              â”‚               â”‚ 3. check target
  â”‚              â”‚               â”‚      (match)  â”‚            â”‚
  â”‚              â”‚               â”‚               â”‚ 4. check target
  â”‚              â”‚               â”‚               â”‚   (no match)â”‚
  â”‚              â”‚               â”‚               â”‚            â”‚ 5. check target
  â”‚              â”‚               â”‚               â”‚            â”‚   (no match)
  â”‚              â”‚               â”‚               â”‚            â”‚
  â”‚              â”‚               â”‚ 6. CAS claim  â”‚               â”‚
  â”‚              â”‚               â”‚â”€â”€â”€â”€â”€â”€â”        â”‚               â”‚
  â”‚              â”‚               â”‚      â”‚ write public memory
  â”‚              â”‚               â”‚â—€â”€â”€â”€â”€â”€â”˜        â”‚               â”‚
  â”‚              â”‚               â”‚   success!    â”‚               â”‚
  â”‚              â”‚               â”‚               â”‚               â”‚
  â”‚              â”‚               â”‚ 7. persist DAGâ”‚               â”‚
  â”‚              â”‚               â”‚ (SQLite local)â”‚               â”‚
  â”‚              â”‚               â”‚               â”‚               â”‚
  â”‚              â”‚               â”‚ 8. start singleton
  â”‚              â”‚               â”‚    coordinator              â”‚
  â”‚              â”‚               â”‚               â”‚               â”‚
  â”‚              â”‚               â”‚ 9. check scope worker
  â”‚              â”‚               â”‚   (proj-a not exist)        â”‚
  â”‚              â”‚               â”‚               â”‚               â”‚
  â”‚              â”‚               â”‚ 10. spawn agent-worker-proj-a
  â”‚              â”‚               â”‚     (new process)           â”‚
  â”‚              â”‚               â”‚               â”‚               â”‚
  â”‚              â”‚               â”‚ 11. submit DAG to worker    â”‚
  â”‚              â”‚               â”‚               â”‚               â”‚
  â”‚              â”‚               â”‚ 12. execute tasks           â”‚
  â”‚              â”‚               â”‚               â”‚               â”‚
  â”‚              â”‚ 13. status update (public memory)           â”‚
  â”‚              â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚               â”‚
  â”‚ 14. poll     â”‚               â”‚               â”‚               â”‚
  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚               â”‚               â”‚
```

---

## å…³é”®é—®é¢˜è§£ç­”

### Q1: åŒä¸€ä½œç”¨åŸŸåªæœ‰ä¸€ä¸ªworkerï¼Œå¦‚ä½•å¼ºåˆ¶ä¿è¯ï¼Ÿ

**A**: æœ¬åœ°æ–‡ä»¶é” + è¿›ç¨‹åæ£€æŸ¥
```rust
pub async fn ensure_singleton_worker(scope: &TaskScope) -> Result<()> {
    let lock_file = format!("/tmp/cis-worker-{}.lock", scope.worker_name());
    
    // 1. å°è¯•è·å–æ–‡ä»¶é”
    let lock = try_lock_exclusive(&lock_file)?;
    
    // 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰åŒåè¿›ç¨‹åœ¨è¿è¡Œ
    let existing = pgrep(&format!("cis-agent-worker.*{}", scope.worker_name()))?;
    
    if existing && lock.is_none() {
        // å·²æœ‰å…¶ä»–è¿›ç¨‹æŒæœ‰é”
        return Err("Worker already running in another process");
    }
    
    // 3. å¯åŠ¨workerï¼ŒæŒæœ‰é”ç›´åˆ°é€€å‡º
    spawn_worker_process(scope, lock).await
}
```

### Q2: Node-1 å´©æºƒäº†æ€ä¹ˆåŠï¼Ÿ

**A**: ç§Ÿçº¦è¿‡æœŸ + é‡æ–°è®¤é¢†
```rust
// DAGè®¤é¢†æ—¶æœ‰ç§Ÿçº¦æ—¶é—´
let claim = DagClaim {
    node_id: "node-1".to_string(),
    claimed_at: now(),
    lease_expires: now() + Duration::from_secs(300),  // 5åˆ†é’Ÿç§Ÿçº¦
};

// å…¶ä»–èŠ‚ç‚¹å®šæœŸæ‰«æè¶…æ—¶çš„DAG
if now() > claim.lease_expires {
    // å¯ä»¥é‡æ–°è®¤é¢†
    self.try_claim(dag_id).await?;
}
```

### Q3: agent-workeræ˜¯è¿›ç¨‹è¿˜æ˜¯çº¿ç¨‹ï¼Ÿ

**A**: æ¨èç‹¬ç«‹è¿›ç¨‹ï¼ŒåŸå› ï¼š
1. **éš”ç¦»æ€§**ï¼šworkerå´©æºƒä¸å½±å“coordinator
2. **èµ„æºæ¸…ç†**ï¼šè¿›ç¨‹é€€å‡ºè‡ªåŠ¨é‡Šæ”¾èµ„æº
3. **ç›‘æ§æ–¹ä¾¿**ï¼šOSçº§åˆ«ç›‘æ§è¿›ç¨‹çŠ¶æ€

```rust
// å¯åŠ¨workerè¿›ç¨‹
Command::new("cis-agent-worker")
    .arg("--scope", "proj-a")
    .arg("--parent-pid", parent_pid.to_string())  // å­¤å„¿è¿›ç¨‹æ£€æµ‹
    .spawn()?;
```

### Q4: å¦‚ä½•é¿å…5cloudå•ç‚¹æ•…éšœï¼Ÿ

**A**: å¤šå…¥å£ + è´Ÿè½½å‡è¡¡
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cloud-1 â”‚   â”‚ cloud-2 â”‚   â”‚ cloud-3 â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚             â”‚             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Room   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ä»»æ„cloudèŠ‚ç‚¹éƒ½å¯ä½œä¸ºå…¥å£ï¼Œé€šè¿‡Roomå¹¿æ’­åˆ°æ‰€æœ‰èŠ‚ç‚¹ã€‚

---

## å®ç°å»ºè®®

### ç»„ä»¶åˆ’åˆ†
```
cis-core/src/
â”œâ”€â”€ coordinator/
â”‚   â”œâ”€â”€ mod.rs                    # Coordinator æ¨¡å—
â”‚   â”œâ”€â”€ singleton.rs              # SingletonDagCoordinator
â”‚   â”œâ”€â”€ worker_pool.rs            # Workerç®¡ç†
â”‚   â””â”€â”€ claim.rs                  # åˆ†å¸ƒå¼è®¤é¢†åè®®
â”‚
â”œâ”€â”€ worker/
â”‚   â”œâ”€â”€ mod.rs                    # AgentWorker
â”‚   â”œâ”€â”€ executor.rs               # ä»»åŠ¡æ‰§è¡Œ
â”‚   â””â”€â”€ lifecycle.rs              # ç”Ÿå‘½å‘¨æœŸç®¡ç†
â”‚
â””â”€â”€ protocol/
    â””â”€â”€ dag_claim.rs              # è®¤é¢†æ¶ˆæ¯æ ¼å¼
```

### é…ç½®ç¤ºä¾‹
```toml
[coordinator]
enable_singleton = true
worker_idle_timeout = 300  # 5åˆ†é’Ÿç©ºé—²é€€å‡º
claim_lease_duration = 300  # 5åˆ†é’Ÿç§Ÿçº¦

[worker]
max_concurrent_tasks = 4
scope_isolation = "project"  # project/user/dag_type/global
```

---

## æ€»ç»“

### âœ… è¿™ä¸ªè®¾è®¡çš„ä¼˜ç‚¹

1. **åˆ†å¸ƒå¼å…¥å£**ï¼š5cloudä½œä¸ºå…¥å£ï¼Œé€šè¿‡Roomå¹¿æ’­ï¼Œå¯æ‰©å±•å¤šä¸ªå…¥å£
2. **æ™ºèƒ½è®¤é¢†**ï¼šåŸºäºtargetæ ‡ç­¾ï¼Œç‰¹å®šèŠ‚ç‚¹æ‰§è¡Œç‰¹å®šä»»åŠ¡
3. **å•ä¾‹ä¿è¯**ï¼šåŒä¸€ä½œç”¨åŸŸåªæœ‰ä¸€ä¸ªworkerï¼Œé¿å…èµ„æºç«äº‰
4. **å¤šé¡¹ç›®éš”ç¦»**ï¼šä¸åŒé¡¹ç›®ç‹¬ç«‹workerï¼Œäº’ä¸å¹²æ‰°
5. **æ•…éšœæ¢å¤**ï¼šç§Ÿçº¦è¿‡æœŸåå¯é‡æ–°è®¤é¢†

### âš ï¸ éœ€è¦æ³¨æ„çš„ç‚¹

1. **è®¤é¢†å†²çª**ï¼šéœ€è¦CASæˆ–åˆ†å¸ƒå¼é”é˜²æ­¢å¤šèŠ‚ç‚¹åŒæ—¶è®¤é¢†
2. **Workerå­¤å„¿è¿›ç¨‹**ï¼šçˆ¶è¿›ç¨‹å´©æºƒæ—¶ï¼Œworkeréœ€è¦è‡ªæ€æˆ–è¢«æ”¶å…»
3. **çŠ¶æ€åŒæ­¥**ï¼šå…¬åŸŸè®°å¿†çš„å†™å…¥å»¶è¿Ÿå¯èƒ½å½±å“çŠ¶æ€æŸ¥è¯¢
4. **ä½œç”¨åŸŸçˆ†ç‚¸**ï¼šé¡¹ç›®è¿‡å¤šæ—¶ï¼Œworkerè¿›ç¨‹æ•°å¯èƒ½è¿‡å¤š

### ğŸ¯ æ¨èå®ç°è·¯å¾„

Phase 1: åŸºç¡€è®¤é¢†
- å…¬åŸŸè®°å¿†CASè®¤é¢†
- æœ¬åœ°SQLiteå­˜å‚¨DAG
- ç®€å•workerçº¿ç¨‹ï¼ˆéè¿›ç¨‹ï¼‰

Phase 2: å•ä¾‹worker
- æ–‡ä»¶é”ä¿è¯å•ä¾‹
- workerè¿›ç¨‹åŒ–
- ç§Ÿçº¦è¿‡æœŸæ£€æµ‹

Phase 3: å¤šä½œç”¨åŸŸ
- é¡¹ç›®éš”ç¦»
- åŠ¨æ€workerç”Ÿå‘½å‘¨æœŸ
- è´Ÿè½½å‡è¡¡ä¼˜åŒ–

è¿™ä¸ªè®¾è®¡æ˜¯å¦æ»¡è¶³ä½ çš„éœ€æ±‚ï¼Ÿéœ€è¦æˆ‘è¯¦ç»†å±•å¼€æŸä¸ªéƒ¨åˆ†å—ï¼Ÿ
