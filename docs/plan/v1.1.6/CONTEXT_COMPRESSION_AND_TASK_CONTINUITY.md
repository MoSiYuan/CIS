# ä¸Šä¸‹æ–‡å‹ç¼©ä¸ä»»åŠ¡å»¶ç»­æ€§è®¾è®¡

> **ç‰ˆæœ¬**: v1.1.6
> **åˆ›å»ºæ—¥æœŸ**: 2026-02-13
> **å…³è”**: [MEMORY_SOURCE_TRUST_DESIGN.md](./MEMORY_SOURCE_TRUST_DESIGN.md)

---

## é—®é¢˜åˆ†æ

### æ ¸å¿ƒçŸ›ç›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¸Šä¸‹æ–‡å‹ç¼©å›°å¢ƒ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  å®Œæ•´ä¿çœŸï¼ˆä¿ç•™æ‰€æœ‰ç»†èŠ‚ï¼‰                                  â”‚
â”‚       â†“                                                        â”‚
â”‚   - ä¸Šä¸‹æ–‡å ç”¨é«˜ï¼ˆæµªè´¹ç©ºé—´ï¼‰                                  â”‚
â”‚   - è¶…è¿‡ LLM ä¸Šä¸‹æ–‡çª—å£                                      â”‚
â”‚   - æˆæœ¬é«˜ï¼ˆtoken è®¡è´¹ï¼‰                                      â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æåº¦å‹ç¼©å›°å¢ƒ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  é«˜åº¦å‹ç¼©ï¼ˆä¸¢å¼ƒç»†èŠ‚ï¼‰                                         â”‚
â”‚       â†“                                                        â”‚
â”‚   - æ•°æ®å¤±çœŸï¼ˆè¯­ä¹‰æ¼‚ç§»ï¼‰                                      â”‚
â”‚   - ä»»åŠ¡å»¶ç»­æ€§ä¸‹é™ï¼ˆAgent ç†è§£åå·®ï¼‰                         â”‚
â”‚   - é‡å¤ç›¸åŒé—®é¢˜ï¼ˆç”¨æˆ·æŠ±æ€¨ï¼‰                                   â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¼ ç»Ÿå‹ç¼©æ–¹æ¡ˆçš„é—®é¢˜

| æ–¹æ¡ˆ | ä¼˜åŠ¿ | åŠ£åŠ¿ | å¤±çœŸå½±å“ |
|------|------|------|----------|
| **æ—¶é—´çª—å£æ»‘åŠ¨**ï¼ˆæœ€è¿‘ N æ¡æ¶ˆæ¯ï¼‰ | ç®€å• | ä¸¢å¤±æ—©æœŸå…³é”®ä¿¡æ¯ | ğŸ”´ é«˜ï¼ˆä»»åŠ¡ç›®æ ‡ä¸¢å¤±ï¼‰ |
| **å…³é”®ä¿¡æ¯æå–**ï¼ˆJSON ç»“æ„ï¼‰ | ç»“æ„åŒ– | ä¸¢å¤±ä¸Šä¸‹æ–‡ç»†èŠ‚ | ğŸ”´ ä¸­ï¼ˆè¯­ä¹‰æ¼‚ç§»ï¼‰ |
| **æ‘˜è¦ç”Ÿæˆ**ï¼ˆAI æ€»ç»“ï¼‰ | å‹ç¼©ç‡é«˜ | æ‘˜è¦ä¸»è§‚æ€§ | ğŸ”´ é«˜ï¼ˆAI è§‚ç‚¹æ±¡æŸ“ï¼‰ |
| **å‘é‡æ£€ç´¢ TopK** | è¯­ä¹‰ç›¸å…³ | å¬å›ç‡ä¸ç¨³å®š | ğŸ”´ ä¸­ï¼ˆæ¼å…³é”®ä¿¡æ¯ï¼‰ |

---

## è®¾è®¡æ–¹æ¡ˆï¼šåˆ†å±‚æ¬¡å¯ä¿¡åº¦å‹ç¼©

### æ ¸å¿ƒæ€æƒ³

ç»“åˆ **MemorySource å¯ä¿¡åº¦ä½“ç³»**ï¼Œå®ç°**åˆ†å±‚æ¸è¿›å‹ç¼©**ï¼š

```
åŸå§‹ä¸Šä¸‹æ–‡ï¼ˆ100K tokensï¼‰
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: UserForced (1.0)           â”‚ â† å®Œæ•´ä¿ç•™ï¼ˆ0% å‹ç¼©ï¼‰
â”‚ - ç”¨æˆ·å¼ºåˆ¶æ ‡è®°ï¼š"è¿™ä¸ªå†³ç­–å¾ˆé‡è¦"                    â”‚
â”‚ - é¡¹ç›®æ¶æ„çº¦å®šï¼ˆRust + SQLiteï¼‰                        â”‚
â”‚ å‹ç¼©åï¼š100% ä¿ç•™                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: UserInput (0.8)              â”‚ â† è½»åº¦å‹ç¼©ï¼ˆ10-20%ï¼‰
â”‚ - ç”¨æˆ·åå¥½ï¼š"æˆ‘å–œæ¬¢æ·±è‰²ä¸»é¢˜"                        â”‚
â”‚ - ç”¨æˆ·ç¡®è®¤çš„æ–¹æ¡ˆ                                     â”‚
â”‚ å‹ç¼©åï¼šä¿ç•™å…³é”®å¥ï¼Œç§»é™¤å†—ä½™                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: AIProposalConfirmed (0.8)    â”‚ â† ä¸­åº¦å‹ç¼©ï¼ˆ30-50%ï¼‰
â”‚ - AI è¾“å‡º + ç”¨æˆ·ç¡®è®¤                                  â”‚
â”‚ - æ€»ç»“æ€§æ–‡æ¡£                                           â”‚
â”‚ å‹ç¼©åï¼šæå–è¦ç‚¹ï¼Œç»“æ„åŒ–å­˜å‚¨                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 4: AIConfirmed (0.5)             â”‚ â† é«˜åº¦å‹ç¼©ï¼ˆ60-80%ï¼‰
â”‚ - AI è‡ªåŠ¨ç¡®è®¤                                         â”‚
â”‚ å‹ç¼©åï¼šæç®€è¡¨ç¤ºæˆ–å‘é‡åŒ–                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 5: AIInferred (0.0)              â”‚ â† æåº¦å‹ç¼©æˆ–ä¸¢å¼ƒ
â”‚ - å•çº¯ AI è¾“å‡º                                         â”‚
â”‚ å‹ç¼©åï¼šåªä¿ç•™å‘é‡åµŒå…¥ï¼Œä¸å ç”¨ä¸Šä¸‹æ–‡                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ€»å‹ç¼©åï¼š~30-40K tokensï¼ˆèŠ‚çœ 60-70%ï¼‰
ä»»åŠ¡å»¶ç»­æ€§ï¼šâœ… é«˜ï¼ˆå…³é”®ä¿¡æ¯å®Œæ•´ï¼‰
```

---

## Phase 1: åˆ†å±‚å‹ç¼©ç®—æ³• (P1.3.1)

### 1.1 å®šä¹‰å‹ç¼©é…ç½®

```rust
/// åˆ†å±‚å‹ç¼©é…ç½®
#[derive(Debug, Clone)]
pub struct CompressionConfig {
    /// UserForced: å‹ç¼©ç‡ï¼ˆ0.0 = ä¸å‹ç¼©ï¼‰
    pub user_forced_ratio: f32,  // é»˜è®¤ 0.0

    /// UserInput: å‹ç¼©ç‡
    pub user_input_ratio: f32,  // é»˜è®¤ 0.15ï¼ˆ15%ï¼‰

    /// AIProposalConfirmed: å‹ç¼©ç‡
    pub ai_proposal_confirmed_ratio: f32,  // é»˜è®¤ 0.4ï¼ˆ40%ï¼‰

    /// AIConfirmed: å‹ç¼©ç‡
    pub ai_confirmed_ratio: f32,  // é»˜è®¤ 0.7ï¼ˆ70%ï¼‰

    /// AIInferred: å‹ç¼©ç‡
    pub ai_inferred_ratio: f32,  // é»˜è®¤ 0.95ï¼ˆ95%ï¼Œå‡ ä¹å…¨å‹ï¼‰

    /// æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆtokensï¼‰
    pub max_context_tokens: usize,  // é»˜è®¤ 40K
}

impl Default for CompressionConfig {
    fn default() -> Self {
        Self {
            user_forced_ratio: 0.0,
            user_input_ratio: 0.15,
            ai_proposal_confirmed_ratio: 0.4,
            ai_confirmed_ratio: 0.7,
            ai_inferred_ratio: 0.95,
            max_context_tokens: 40_000,
        }
    }
}
```

### 1.2 åˆ†å±‚å‹ç¼©å®ç°

```rust
impl ContextService {
    /// åˆ†å±‚å‹ç¼©ä¸Šä¸‹æ–‡
    ///
    /// # å‚æ•°
    /// - `memories`: æ‰€æœ‰è®°å¿†ï¼ˆæŒ‰å¯ä¿¡åº¦åˆ†å±‚ï¼‰
    /// - `config`: å‹ç¼©é…ç½®
    ///
    /// # è¿”å›
    /// (å‹ç¼©åä¸Šä¸‹æ–‡, å‹ç¼©æŠ¥å‘Š)
    pub async fn compress_context_layered(
        &self,
        memories: Vec<MemoryEntry>,
        config: CompressionConfig,
    ) -> Result<(String, CompressionReport)> {
        let mut layers: HashMap<MemorySource, Vec<_>> = HashMap::new();
        let mut report = CompressionReport {
            original_tokens: 0,
            compressed_tokens: 0,
            layer_stats: HashMap::new(),
        };

        // 1. æŒ‰æ¥æºåˆ†å±‚
        for memory in memories {
            let token_count = self.count_tokens(&memory.value);
            report.original_tokens += token_count;

            layers.entry(memory.source)
                .or_insert_with(Vec::new)
                .push((memory, token_count));
        }

        // 2. åˆ†å±‚å‹ç¼©
        let mut compressed_context = String::new();

        // Layer 1: UserForcedï¼ˆå®Œæ•´ä¿ç•™ï¼‰
        if let Some(items) = layers.remove(&MemorySource::UserForced) {
            for (memory, tokens) in items {
                compressed_context.push_str(&format!(
                    "[USER_FORCED] {}\n",
                    String::from_utf8_lossy(&memory.value)
                ));
                report.compressed_tokens += tokens;
                report.layer_stats.insert("UserForced", LayerStat {
                    original: tokens,
                    compressed: tokens,
                    ratio: 0.0,
                });
            }
        }

        // Layer 2: UserInputï¼ˆè½»åº¦å‹ç¼©ï¼‰
        if let Some(items) = layers.remove(&MemorySource::UserInput) {
            let compressed = self.compress_layer(
                items,
                config.user_input_ratio,
                CompressionLevel::Light,
            ).await?;

            report.compressed_tokens += compressed.total_tokens;
            report.layer_stats.insert("UserInput", compressed.stat);
            compressed_context.push_str(&compressed.text);
        }

        // Layer 3: AIProposalConfirmedï¼ˆä¸­åº¦å‹ç¼©ï¼‰
        if let Some(items) = layers.remove(&MemorySource::AIProposalConfirmed) {
            let compressed = self.compress_layer(
                items,
                config.ai_proposal_confirmed_ratio,
                CompressionLevel::Medium,
            ).await?;

            report.compressed_tokens += compressed.total_tokens;
            report.layer_stats.insert("AIProposalConfirmed", compressed.stat);
            compressed_context.push_str(&compressed.text);
        }

        // Layer 4: AIConfirmedï¼ˆé«˜åº¦å‹ç¼©ï¼‰
        if let Some(items) = layers.remove(&MemorySource::AIConfirmed) {
            let compressed = self.compress_layer(
                items,
                config.ai_confirmed_ratio,
                CompressionLevel::Heavy,
            ).await?;

            report.compressed_tokens += compressed.total_tokens;
            report.layer_stats.insert("AIConfirmed", compressed.stat);
            compressed_context.push_str(&compressed.text);
        }

        // Layer 5: AIInferredï¼ˆæåº¦å‹ç¼©ï¼‰
        if let Some(items) = layers.remove(&MemorySource::AIInferred) {
            let compressed = self.compress_layer(
                items,
                config.ai_inferred_ratio,
                CompressionLevel::Extreme,
            ).await?;

            report.compressed_tokens += compressed.total_tokens;
            report.layer_stats.insert("AIInferred", compressed.stat);
            compressed_context.push_str(&compressed.text);
        }

        Ok((compressed_context, report))
    }

    /// å‹ç¼©å•å±‚è®°å¿†
    async fn compress_layer(
        &self,
        items: Vec<(MemoryEntry, usize)>,  // (entry, token_count)
        target_ratio: f32,
        level: CompressionLevel,
    ) -> Result<CompressedLayer> {
        let original_tokens: usize = items.iter().map(|(_, t)| t).sum();
        let target_tokens = (original_tokens as f32 * (1.0 - target_ratio)) as usize;

        let mut compressed = String::new();
        let mut compressed_tokens = 0;

        match level {
            CompressionLevel::None => {
                // å®Œæ•´ä¿ç•™
                for (memory, _) in items {
                    compressed.push_str(&String::from_utf8_lossy(&memory.value));
                    compressed.push_str("\n");
                }
                compressed_tokens = original_tokens;
            }

            CompressionLevel::Light => {
                // è½»åº¦å‹ç¼©ï¼šç§»é™¤å†—ä½™ï¼Œä¿ç•™å…³é”®å¥
                for (memory, _) in items {
                    let text = String::from_utf8_lossy(&memory.value);
                    let sentences = self.extract_key_sentences(&text, 0.8).await?;
                    compressed.push_str(&sentences.join(" "));
                    compressed.push_str("\n");
                }
                compressed_tokens = self.count_tokens(&compressed);
            }

            CompressionLevel::Medium => {
                // ä¸­åº¦å‹ç¼©ï¼šæå–è¦ç‚¹ï¼Œç»“æ„åŒ–
                for (memory, _) in items {
                    let text = String::from_utf8_lossy(&memory.value);
                    let summary = self.extract_summary(&text).await?;
                    compressed.push_str(&format!("- {}\n", summary));
                }
                compressed_tokens = self.count_tokens(&compressed);
            }

            CompressionLevel::Heavy => {
                // é«˜åº¦å‹ç¼©ï¼šæç®€è¡¨ç¤º
                for (memory, _) in items {
                    let text = String::from_utf8_lossy(&memory.value);
                    let keywords = self.extract_keywords(&text, 3).await?;  // å‰ 3 ä¸ªå…³é”®è¯
                    compressed.push_str(&format!("[{}]\n", keywords.join(", ")));
                }
                compressed_tokens = self.count_tokens(&compressed);
            }

            CompressionLevel::Extreme => {
                // æåº¦å‹ç¼©ï¼šå‘é‡åŒ–ï¼ˆåªä¿ç•™å‘é‡åµŒå…¥ï¼‰
                // ğŸ”¥ ä¸å ç”¨ä¸Šä¸‹æ–‡ï¼Œåªä¿ç•™å‘é‡ç´¢å¼•
                for (memory, _) in items {
                    // å‘é‡åŒ–ï¼šå°†æ–‡æœ¬è½¬ä¸ºå‘é‡ ID
                    let vec_id = self.vector_storage.get_vector_id(&memory.key).await?;
                    compressed.push_str(&format!("<VEC:{}> ", vec_id));
                }
                compressed_tokens = items.len();  // æ¯ä¸ª <VEC:id> ç®—ä½œ 1 token
            }
        }

        Ok(CompressedLayer {
            text: compressed,
            total_tokens: compressed_tokens,
            stat: LayerStat {
                original: original_tokens,
                compressed: compressed_tokens,
                ratio: if original_tokens > 0 {
                    (original_tokens - compressed_tokens) as f32 / original_tokens as f32
                } else {
                    0.0
                },
            },
        })
    }
}

#[derive(Debug)]
pub struct CompressedLayer {
    pub text: String,
    pub total_tokens: usize,
    pub stat: LayerStat,
}

#[derive(Debug)]
pub struct LayerStat {
    pub original: usize,
    pub compressed: usize,
    pub ratio: f32,  // å‹ç¼©ç‡
}

pub enum CompressionLevel {
    None,       // å®Œæ•´ä¿ç•™ï¼ˆ0% å‹ç¼©ï¼‰
    Light,       // è½»åº¦å‹ç¼©ï¼ˆ10-20%ï¼‰
    Medium,      // ä¸­åº¦å‹ç¼©ï¼ˆ30-50%ï¼‰
    Heavy,       // é«˜åº¦å‹ç¼©ï¼ˆ60-80%ï¼‰
    Extreme,     // æåº¦å‹ç¼©ï¼ˆ90-95%ï¼‰
}
```

---

## Phase 2: è¯­ä¹‰å»é‡ä¸èšç±» (P1.3.2)

### é—®é¢˜

å³ä½¿åˆ†å±‚å‹ç¼©ï¼Œä»å¯èƒ½å‡ºç°ï¼š
- **é‡å¤ä¿¡æ¯**ï¼šç”¨æˆ·å¤šæ¬¡æåˆ°ç›¸åŒåå¥½
- **è¯­ä¹‰ç›¸è¿‘**ï¼šä¸åŒè®°å¿†è¡¨è¾¾ç›¸ä¼¼å«ä¹‰
- **ä¸Šä¸‹æ–‡æµªè´¹**ï¼šé‡å¤å†…å®¹å ç”¨ç©ºé—´

### è§£å†³æ–¹æ¡ˆï¼šè¯­ä¹‰èšç±»å»é‡

```rust
impl ContextService {
    /// è¯­ä¹‰èšç±»å»é‡
    ///
    /// # ç®—æ³•
    /// 1. å°†æ‰€æœ‰è®°å¿†è½¬ä¸ºå‘é‡åµŒå…¥
    /// 2. DBSCAN èšç±»ï¼ˆç›¸ä¼¼åº¦é˜ˆå€¼ 0.85ï¼‰
    /// 3. æ¯ä¸ªèšç±»é€‰æ‹©æœ€é«˜å¯ä¿¡åº¦çš„ä»£è¡¨
    /// 4. ç§»é™¤èšç±»å†…çš„å…¶ä»–æˆå‘˜
    pub async fn semantic_dedup_compress(
        &self,
        memories: Vec<MemoryEntry>,
        similarity_threshold: f32,  // é»˜è®¤ 0.85
    ) -> Result<(Vec<MemoryEntry>, DedupReport)> {
        let mut report = DedupReport {
            original_count: memories.len(),
            deduped_count: 0,
            clusters_found: 0,
            tokens_saved: 0,
        };

        // 1. è·å–æ‰€æœ‰å‘é‡åµŒå…¥
        let mut embeddings = Vec::new();
        for memory in &memories {
            let vec = self.vector_storage.get_embedding(&memory.key).await?;
            embeddings.push((memory.clone(), vec));
        }

        // 2. DBSCAN èšç±»
        let clusters = self.dbscan_cluster(
            embeddings,
            similarity_threshold,
            min_points: 2,  // è‡³å°‘ 2 ä¸ªç‚¹æ‰ç®—èšç±»
        ).await?;

        report.clusters_found = clusters.len();

        // 3. æ¯ä¸ªèšç±»é€‰æ‹©ä»£è¡¨ï¼ˆæœ€é«˜å¯ä¿¡åº¦ï¼‰
        let mut deduped_memories = Vec::new();
        let mut to_remove = HashSet::new();

        for cluster in clusters {
            if cluster.len() <= 1 {
                // å•ç‚¹èšç±»ï¼Œä¿ç•™
                deduped_memories.push(cluster[0].0.clone());
                continue;
            }

            // æ‰¾åˆ°æœ€é«˜å¯ä¿¡åº¦çš„è®°å¿†
            let best = cluster.iter()
                .max_by_key(|(mem, _)| mem.source.confidence())
                .unwrap();

            deduped_memories.push(best.0.clone());

            // æ ‡è®°å…¶ä»–ä¸ºå¾…åˆ é™¤
            for (mem, _) in cluster {
                if mem.key != best.0.key {
                    to_remove.insert(mem.key.clone());
                    report.tokens_saved += self.count_tokens(&mem.value);
                }
            }
        }

        report.deduped_count = memories.len() - deduped_memories.len();

        tracing::info!(
            "Semantic dedup: {} -> {} memories, saved {} tokens",
            memories.len(),
            deduped_memories.len(),
            report.tokens_saved
        );

        Ok((deduped_memories, report))
    }

    /// DBSCAN èšç±»ï¼ˆåŸºäºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    async fn dbscan_cluster(
        &self,
        embeddings: Vec<(MemoryEntry, Vec<f32>)>,
        similarity_threshold: f32,
        min_points: usize,
    ) -> Result<Vec<Vec<(MemoryEntry, Vec<f32>)>> {
        // ç®€åŒ–çš„ DBSCAN å®ç°
        let mut clusters = Vec::new();
        let mut visited = HashSet::new();

        for (i, (mem_i, vec_i)) in embeddings.iter().enumerate() {
            if visited.contains(&mem_i.key) {
                continue;
            }

            // æ‰¾é‚»åŸŸç‚¹
            let mut neighbors = Vec::new();
            for (mem_j, vec_j) in &embeddings {
                if i == embeddings.iter().position(|(m, _)| m.key == mem_j.key).unwrap() {
                    continue;
                }

                let similarity = cosine_similarity(vec_i, vec_j);
                if similarity >= similarity_threshold {
                    neighbors.push((mem_j.clone(), vec_j.clone()));
                }
            }

            if neighbors.len() < min_points {
                // å™ªå£°ç‚¹
                visited.insert(mem_i.key.clone());
                continue;
            }

            // åˆ›å»ºæ–°èšç±»
            let mut cluster = vec![(mem_i.clone(), vec_i.clone())];
            visited.insert(mem_i.key.clone());

            // æ‰©å±•èšç±»ï¼ˆé€’å½’ï¼‰
            let mut idx = 0;
            while idx < neighbors.len() {
                let (mem_n, vec_n) = &neighbors[idx];
                if !visited.contains(&mem_n.key) {
                    visited.insert(mem_n.key.clone());
                    cluster.push((mem_n.clone(), vec_n.clone()));

                    // æ‰¾é‚»åŸŸçš„é‚»åŸŸ
                    for (mem_m, vec_m) in &embeddings {
                        if visited.contains(&mem_m.key) {
                            continue;
                        }

                        let sim = cosine_similarity(vec_n, vec_m);
                        if sim >= similarity_threshold {
                            neighbors.push((mem_m.clone(), vec_m.clone()));
                        }
                    }
                }
                idx += 1;
            }

            clusters.push(cluster);
        }

        Ok(clusters)
    }
}

#[derive(Debug)]
pub struct DedupReport {
    pub original_count: usize,
    pub deduped_count: usize,
    pub clusters_found: usize,
    pub tokens_saved: usize,
}
```

---

## Phase 3: è‡ªé€‚åº”å‹ç¼©æ¯”è°ƒæ•´ (P1.3.3)

### é—®é¢˜

å›ºå®šå‹ç¼©æ¯”å¯èƒ½å¯¼è‡´ï¼š
- **å‹ç¼©ä¸è¶³**ï¼šä¸Šä¸‹æ–‡ä»ç„¶è¶…é•¿
- **è¿‡åº¦å‹ç¼©**ï¼šä»»åŠ¡å»¶ç»­æ€§ä¸‹é™

### è§£å†³æ–¹æ¡ˆï¼šåŠ¨æ€è°ƒæ•´å‹ç¼©æ¯”

```rust
impl ContextService {
    /// è‡ªé€‚åº”å‹ç¼©ï¼ˆæ ¹æ®ä¸Šä¸‹æ–‡é•¿åº¦åŠ¨æ€è°ƒæ•´ï¼‰
    pub async fn adaptive_compress(
        &self,
        memories: Vec<MemoryEntry>,
        base_config: CompressionConfig,
        max_tokens: usize,
    ) -> Result<(String, CompressionReport)> {
        let mut config = base_config.clone();
        let mut iteration = 0;
        let max_iterations = 5;

        loop {
            iteration += 1;
            if iteration > max_iterations {
                return Err(CisError::context(
                    format!("Failed to compress to {} tokens after {} iterations", max_tokens, max_iterations)
                ));
            }

            // 1. å°è¯•å‹ç¼©
            let (compressed, report) = self.compress_context_layered(
                memories.clone(),
                config.clone(),
            ).await?;

            // 2. æ£€æŸ¥é•¿åº¦
            let compressed_tokens = self.count_tokens(&compressed);

            if compressed_tokens <= max_tokens {
                // âœ… è¾¾åˆ°ç›®æ ‡
                tracing::info!(
                    "Adaptive compress converged in {} iterations: {} -> {} tokens ({}% saved)",
                    iteration,
                    report.original_tokens,
                    compressed_tokens,
                    (report.original_tokens - compressed_tokens) * 100 / report.original_tokens
                );
                return Ok((compressed, report));
            }

            // 3. è¶…å‡ºç›®æ ‡ï¼Œå¢åŠ å‹ç¼©æ¯”
            let over_ratio = (compressed_tokens - max_tokens) as f32 / compressed_tokens as f32;
            tracing::debug!(
                "Iteration {}: {} tokens (target {}), over by {:.1}%, increasing compression",
                iteration,
                compressed_tokens,
                max_tokens,
                over_ratio * 100.0
            );

            // æŒ‰æ¯”ä¾‹å¢åŠ å„å±‚å‹ç¼©æ¯”
            config.user_input_ratio = (config.user_input_ratio + over_ratio * 0.5).min(0.8);
            config.ai_proposal_confirmed_ratio = (config.ai_proposal_confirmed_ratio + over_ratio * 0.6).min(0.9);
            config.ai_confirmed_ratio = (config.ai_confirmed_ratio + over_ratio * 0.7).min(0.95);
            config.ai_inferred_ratio = (config.ai_inferred_ratio + over_ratio * 0.8).min(0.98);

            // UserForced æ°¸ä¸å‹ç¼©ï¼ˆä¿æŒ 0.0ï¼‰
        }
    }
}
```

---

## Phase 4: ä»»åŠ¡å»¶ç»­æ€§ä¿éšœ (P1.3.4)

### å…³é”®é—®é¢˜

å‹ç¼©åå¦‚ä½•ç¡®ä¿ Agent ä»èƒ½å‡†ç¡®ç†è§£ä»»åŠ¡ç›®æ ‡ï¼Ÿ

### è§£å†³æ–¹æ¡ˆ 1: ä»»åŠ¡é“¾è¿½è¸ª

```rust
/// ä»»åŠ¡é“¾ï¼ˆè¿½è¸ªä»»åŠ¡æ¼”è¿›ï¼‰
#[derive(Debug, Clone)]
pub struct TaskChain {
    pub task_id: String,
    pub created_at: i64,
    pub initial_prompt: String,           // åˆå§‹ä»»åŠ¡æè¿°ï¼ˆUserForced, å®Œæ•´ä¿ç•™ï¼‰
    pub evolution_steps: Vec<TaskStep>,    // ä»»åŠ¡æ¼”è¿›å†å²
}

#[derive(Debug, Clone)]
pub struct TaskStep {
    pub step_id: String,
    pub timestamp: i64,
    pub action: String,                   // æ“ä½œæè¿°
    pub result: String,                   // ç»“æœ
    pub next_tasks: Vec<String>,         // è¡ç”Ÿä»»åŠ¡
}

impl ContextService {
    /// æ„å»ºä»»åŠ¡é“¾ä¸Šä¸‹æ–‡ï¼ˆç¡®ä¿å»¶ç»­æ€§ï¼‰
    pub async fn build_task_chain_context(
        &self,
        task_chain: &TaskChain,
    ) -> Result<String> {
        let mut context = String::new();

        // 1. åˆå§‹ä»»åŠ¡ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
        context.push_str(&format!(
            "[TASK_INIT] {}\n",
            task_chain.initial_prompt
        ));

        // 2. æ¼”è¿›è·¯å¾„ï¼ˆè½»åº¦å‹ç¼©ï¼‰
        context.push_str("[EVOLUTION_PATH]\n");
        for (idx, step) in task_chain.evolution_steps.iter().enumerate() {
            context.push_str(&format!(
                "{}. {} -> {}\n",
                idx + 1,
                step.action,
                step.result
            ));
        }

        // 3. å½“å‰çŠ¶æ€ï¼ˆä¸­åº¦å‹ç¼©ï¼‰
        if let Some(latest) = task_chain.evolution_steps.last() {
            context.push_str(&format!(
                "[CURRENT_STATUS] Last action: {}, Result: {}\n",
                latest.action,
                latest.result
            ));
        }

        Ok(context)
    }
}
```

### è§£å†³æ–¹æ¡ˆ 2: å…³é”®ä¿¡æ¯é”šç‚¹

```rust
impl ContextService {
    /// æå–å…³é”®ä¿¡æ¯é”šç‚¹ï¼ˆå¿…é¡»ä¿ç•™ï¼‰
    pub async fn extract_anchors(
        &self,
        memories: Vec<MemoryEntry>,
    ) -> Result<Vec<Anchor>> {
        let mut anchors = Vec::new();

        for memory in memories {
            match memory.source {
                MemorySource::UserForced => {
                    // ğŸ”¥ å¼ºåˆ¶é”šç‚¹ï¼šå®Œæ•´ä¿ç•™
                    anchors.push(Anchor {
                        key: memory.key.clone(),
                        text: String::from_utf8_lossy(&memory.value),
                        priority: AnchorPriority::Critical,
                        compressible: false,
                    });
                }

                MemorySource::UserInput => {
                    // æå–å…³é”®å¥ï¼ˆè½»åº¦å‹ç¼©ï¼‰
                    let sentences = self.extract_key_sentences(
                        &String::from_utf8_lossy(&memory.value),
                        0.9,  // é«˜é˜ˆå€¼
                    ).await?;

                    for sentence in sentences {
                        anchors.push(Anchor {
                            key: format!("{}#anchor", memory.key),
                            text: sentence,
                            priority: AnchorPriority::High,
                            compressible: true,
                        });
                    }
                }

                _ => {
                    // å…¶ä»–æ¥æºï¼šå¯é€‰å‹ç¼©
                    let summary = self.extract_summary(
                        &String::from_utf8_lossy(&memory.value)
                    ).await?;

                    anchors.push(Anchor {
                        key: memory.key.clone(),
                        text: summary,
                        priority: AnchorPriority::Medium,
                        compressible: true,
                    });
                }
            }
        }

        Ok(anchors)
    }
}

#[derive(Debug)]
pub struct Anchor {
    pub key: String,
    pub text: String,
    pub priority: AnchorPriority,
    pub compressible: bool,  // æ˜¯å¦å¯å‹ç¼©
}

#[derive(Debug)]
pub enum AnchorPriority {
    Critical,  // ä¸å¯å‹ç¼©ï¼ˆUserForcedï¼‰
    High,      // è½»åº¦å‹ç¼©
    Medium,    // ä¸­åº¦å‹ç¼©
    Low,       // é«˜åº¦å‹ç¼©
}
```

---

## å®Œæ•´ä½¿ç”¨æµç¨‹

### åœºæ™¯ï¼šé•¿å¯¹è¯ä»»åŠ¡å»¶ç»­

```rust
// ========== ç¬¬ä¸€æ­¥ï¼šè·å–æ‰€æœ‰ç›¸å…³è®°å¿† ==========
let memories = service.get_memories_by_task("task-123").await?;

// ========== ç¬¬äºŒæ­¥ï¼šè¯­ä¹‰å»é‡ ==========
let (deduped, dedup_report) = service.semantic_dedup_compress(
    memories,
    0.85,  // ç›¸ä¼¼åº¦é˜ˆå€¼
).await?;

println!("å»é‡ï¼š{} -> {} è®°å¿†ï¼ŒèŠ‚çœ {} tokens",
    dedup_report.original_count,
    dedup_report.deduped_count,
    dedup_report.tokens_saved
);

// ========== ç¬¬ä¸‰æ­¥ï¼šè‡ªé€‚åº”å‹ç¼© ==========
let (compressed, compress_report) = service.adaptive_compress(
    deduped,
    CompressionConfig::default(),
    40_000,  // ç›®æ ‡ 40K tokens
).await?;

println!("å‹ç¼©ï¼š{} -> {} tokens ({}% èŠ‚çœ)",
    compress_report.original_tokens,
    compress_report.compressed_tokens,
    (compress_report.original_tokens - compress_report.compressed_tokens) * 100 / compress_report.original_tokens
);

// ========== ç¬¬å››æ­¥ï¼šæ„å»ºä»»åŠ¡é“¾ä¸Šä¸‹æ–‡ ==========
let task_chain = service.get_task_chain("task-123").await?;
let task_context = service.build_task_chain_context(&task_chain).await?;

// ========== ç¬¬äº”æ­¥ï¼šç»„åˆæœ€ç»ˆä¸Šä¸‹æ–‡ ==========
let final_context = format!(
    "{}\n{}\n{}",
    task_context,      // ä»»åŠ¡é“¾ï¼ˆä¿éšœå»¶ç»­æ€§ï¼‰
    "[COMPRESSED_CONTEXT]",  // åˆ†éš”ç¬¦
    compressed         // å‹ç¼©åçš„è®°å¿†ï¼ˆèŠ‚çœç©ºé—´ï¼‰
);

// ========== ç¬¬å…­æ­¥ï¼šå‘é€ç»™ Agent ==========
let response = agent.generate(&final_context).await?;
```

---

## æ€§èƒ½é¢„æµ‹

### å‹ç¼©æ•ˆæœ

| åœºæ™¯ | åŸå§‹ tokens | å‹ç¼©å tokens | èŠ‚çœç‡ | ä»»åŠ¡å»¶ç»­æ€§ |
|------|-------------|---------------|--------|------------|
| **çŸ­ä»»åŠ¡**ï¼ˆ50 æ¡è®°å¿†ï¼‰ | 50K | 18K | 64% | âœ… é«˜ |
| **ä¸­ç­‰ä»»åŠ¡**ï¼ˆ200 æ¡è®°å¿†ï¼‰ | 150K | 42K | 72% | âœ… é«˜ |
| **é•¿ä»»åŠ¡**ï¼ˆ500 æ¡è®°å¿†ï¼‰ | 400K | 65K | 84% | âš ï¸ ä¸­ |

### å»ç¼©åè´¨é‡å¯¹æ¯”

| æ–¹æ¡ˆ | è¯­ä¹‰ä¿ç•™åº¦ | ä»»åŠ¡å»¶ç»­æ€§ | ç©ºé—´èŠ‚çœ |
|------|-----------|-----------|---------|
| **æ—¶é—´çª—å£æ»‘åŠ¨** | ğŸ”´ 60% | ğŸ”´ ä½ | âœ… 80% |
| **AI æ‘˜è¦ç”Ÿæˆ** | ğŸ”´ 70% | ğŸ”´ ä¸­ | âœ… 75% |
| **æœ¬æ–¹æ¡ˆï¼ˆåˆ†å±‚å‹ç¼©ï¼‰** | âœ… 85% | âœ… é«˜ | âœ… 70% |

---

## é£é™©ä¸ç¼“è§£

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|----------|
| å‹ç¼©æ¯”è¿‡é«˜å¯¼è‡´å¤±çœŸ | ä»»åŠ¡å»¶ç»­æ€§ä¸‹é™ | è‡ªé€‚åº”è°ƒæ•´ï¼Œé€æ­¥å¢åŠ å‹ç¼©æ¯” |
| è¯­ä¹‰å»é‡è¯¯åˆ å…³é”®ä¿¡æ¯ | é—æ¼é‡è¦ä¸Šä¸‹æ–‡ | DBSCAN min_points å‚æ•°ï¼Œä¿å®ˆé˜ˆå€¼ |
| æåº¦å‹ç¼©åå‘é‡æ£€ç´¢å¤±æ•ˆ | Agent ç†è§£åå·® | ä¿ç•™ <VEC:id> æ ‡è®°ï¼Œæ”¯æŒå‘é‡æ£€ç´¢å›æº¯ |
| å‹ç¼©ç®—æ³•æ€§èƒ½å¼€é”€ | å»¶è¿Ÿå¢åŠ  | æ‰¹é‡å¤„ç†ï¼Œå¹¶è¡Œèšç±» |

---

## å®æ–½è®¡åˆ’

### Phase 1: åˆ†å±‚å‹ç¼© (P1.3.1)
- [ ] å®ç° `CompressionConfig`
- [ ] å®ç° `compress_context_layered()`
- [ ] å®ç°å„çº§å‹ç¼©ç®—æ³•ï¼ˆLight/Medium/Heavy/Extremeï¼‰
- [ ] å•å…ƒæµ‹è¯•

### Phase 2: è¯­ä¹‰å»é‡ (P1.3.2)
- [ ] å®ç° DBSCAN èšç±»
- [ ] å®ç° `semantic_dedup_compress()`
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆå¹¶è¡Œç›¸ä¼¼åº¦è®¡ç®—ï¼‰
- [ ] åŸºå‡†æµ‹è¯•

### Phase 3: è‡ªé€‚åº”è°ƒæ•´ (P1.3.3)
- [ ] å®ç° `adaptive_compress()`
- [ ] å‚æ•°æ”¶æ•›ç®—æ³•ä¼˜åŒ–
- [ ] å‹ç¼©è´¨é‡è¯„ä¼°

### Phase 4: ä»»åŠ¡å»¶ç»­æ€§ (P1.3.4)
- [ ] å®ç° `TaskChain` è¿½è¸ª
- [ ] å®ç°å…³é”®ä¿¡æ¯é”šç‚¹æå–
- [ ] é›†æˆåˆ° Agent ç”Ÿæˆæµç¨‹

---

**ç»´æŠ¤è€…**: CIS v1.1.6 Team
**æœ€åæ›´æ–°**: 2026-02-13
